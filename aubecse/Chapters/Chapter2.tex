% Chapter 2
\chapter{RELATED WORK} % Chapter Title in ALL CAPSacs
A significant amount of research and work has gone into the quadcopter. There have been several algorithms for controlling the stability of the quad such as PID(Proportional-Integral-Derivative) and Fuzzy Logic. With improvements to open source image processing libraries like OpenCV and the development of RaspberryPi microcomputer, the capability and use of drones for various activities have increased. Alex G. Kendall, Nishaad N. Salvapantula and Karl A. Stol developed an on-board object-tracking control of a quadcopter with monocular vision[1]. This project used a RapsberryPi for processing along with a camera module and sensors as input to the OpenCV library for object tracking. While our project also makes use of the Rpi and OpenCV for image processing, it does not perform object tracking. It takes pictures which are then used for panorama stitching and 3D model reconstruction. Their quadcopter could detect the relative positions of static objects but it could not dynamically follow objects. Our project does not deal with tracking and we have focused largely on the flight stability and image processing modules.
Quadcopter control has mostly been through Radio Control joysticks. Since everybody owns an Android phone now, we developed a virtual joystick interface to control the flight of the quadcopter as an Android app. The app is also used for directing image-processing functions of the drone. Since our quadcopter's functions are panorama stitching and 3D reconstruction, we needed to develop an interface for rendering the results.  A. Zul Azfar and Hazry Desa[2] had developed a Graphical User Interface for monitoring the flight dynamics and orientation of a remotely-operated quadcopter. The GUI was developed using LABView software. Basically, the GUI on the PC accurately captured the motion of the quadcopter as images which were rendered using LabVIEW software. The quadcopter’s processing was done on-board using Arduino microcontroller and the balancing and stability were managed using an IMU sensor. This was a path-breaking paper as it demonstrated how an unmanned aerial vehicle could be controlled from a remote station. Priyanga M. And Raja Ramanan [3] developed a UAV for Video Surveillance to prevent unauthorized soil-mining operations. It used a Rpi for on-board processing of live feeds from a webcam. The videos could be viewed on a webpage in real-time using WiFi. The drone used a GPS to calculate position and follow the target. In our project, signals from the app are sent as JSON-encoded data using Wifi to the Python server running on the quadcopter and corresponding results from image processing/pictures aboard the drone are rendered in a browser interface by a laptop on the ground. Since our project does not involve object-tracking, it does not use a GPS receiver but the quadcopter itself is controlled remotely using WiFi by the Android App.
Image processing on-board the quadcopter has been implemented by K.S. Shilpashree, Lokesha H and Hadimani Shivkumar [6] in their paper, “Implementation of Image Processing on Raspberry Pi”. They have described the purpose of applying image-enhancing algorithms to improve the quality of the images taken by the drone since the quality of the images may be compromised due to unstable flight. Image-enhancing algorithms such as Rudin-Osher-Fatemi de-noising model (ROF) have been implemented. 
We had tried to implement 3D reconstruction aboard the drone but due to several hardware incompatibility issues and heavy processing required, we were forced to move it to a remote laptop. Shawn McCann's thesis on “3D Reconstruction from Multiple Images” [5] has tried to identify various techniques for dense and sparse reconstructions using Structure from Motion(SfM) algorithms. Our project makes use of VLFeat which has SfM support and OpenCV which offers a variety of useful libraries for feature detection and matching. In both projects, Bundle Adjustment module was used to minimize reprojection errors and generate sparse point clouds. While [5] rendered the point clouds using third-party tools(MeshLab), our project uses an interactive JS library called, threeJS which renders the point cloud on a browser. Drone technology has advanced enormously along the lines of photography, surveillance, exploration and mapping of terrains and delivery. We were inspired by the fact the mobility and usability of drones from these projects and hence, decided to build one which combined panorama-stitching and 3D reconstruction.
